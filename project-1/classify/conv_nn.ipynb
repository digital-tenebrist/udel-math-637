{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "successful-slave",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "1. Compound pipeline\n",
    "    1. Convolution Stage\n",
    "    1. MaxPooling Stage\n",
    "1. Multiple Stages\n",
    "1. Data already ready into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-liability",
   "metadata": {},
   "source": [
    "## Imports and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radio-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import font_utils.load_font as LF\n",
    "\n",
    "TRIMMED_PATH='/data/udel-ms-data-science/math-637/project-1/char-fonts/trimmed'\n",
    "ALL_FONTS_CSV=f'{TRIMMED_PATH}/all_fonts.csv'\n",
    "\n",
    "DATA_COLS=[f'r{row}c{col}' for row in range(20) for col in range(20)]\n",
    "TARGET_COL=['font_class']\n",
    "META_COLS=['m_label', 'font', 'variant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-kingdom",
   "metadata": {},
   "source": [
    "## Read All Font Data\n",
    "\n",
    "1. Randomly shuffle the data first to mix the classes within the data set\n",
    "1. m_label - the character encoded as ASCII\n",
    "1. font\n",
    "1. font variant\n",
    "1. class_label (TARGET)\n",
    "    1. 1 - The font character is the given font class\n",
    "    1. 0 - The font character is not the given font class\n",
    "1. r0c0...r19c19 (400 elements in raw image data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "shaped-backing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mo (3470, 404)\n",
      "os (2726, 404)\n",
      "ss (5702, 404)\n",
      "tr (2479, 404)\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.read_csv(ALL_FONTS_CSV).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "class_counts = {\n",
    "    cc_i:cc_v for cc_i, cc_v in all_df.groupby(by='font_class').count().m_label.items()\n",
    "}\n",
    "\n",
    "BY_CLASS = {c:all_df.loc[all_df.font_class == c] for c in ['mo', 'os', 'ss', 'tr']}\n",
    "\n",
    "WITHOUT = {\n",
    "    'mo' : ['os', 'ss', 'tr'],\n",
    "    'os' : ['mo', 'ss', 'tr'],\n",
    "    'ss' : ['mo', 'os', 'tr'],\n",
    "    'tr' : ['mo', 'os', 'ss']    \n",
    "}\n",
    "\n",
    "RAW_INPUT_DICT = dict()\n",
    "for k,v in class_counts.items():\n",
    "    one_third = int(v/3)\n",
    "    others = list()\n",
    "    for c in WITHOUT[k]:\n",
    "        others.append(BY_CLASS[c].sample(frac=float(one_third/class_counts[c])).reset_index(drop=True))\n",
    "    others.append(BY_CLASS[k])\n",
    "    t_df = pd.DataFrame().append(others).sample(frac=1).reset_index(drop=True)\n",
    "    t_df['font_class'] = np.where(t_df.font_class == k, 1, 0)\n",
    "    t_df['font_class'] = t_df['font_class'].astype(int)\n",
    "    RAW_INPUT_DICT[k] = t_df\n",
    "    \n",
    "for c, df in RAW_INPUT_DICT.items():\n",
    "    print(f'{c} {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-notebook",
   "metadata": {},
   "source": [
    "## Split Data Into Train/Test\n",
    "\n",
    "1. X cols: r0c0,...,r19c19\n",
    "1. Y cols: font_class\n",
    "1. Others: m_label, font, variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "viral-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2248    [[222, 135, 145, 250, 153, 1, 1, 1, 1, 1, 1, 1...\n",
       "2078    [[1, 1, 1, 29, 114, 114, 220, 255, 255, 255, 2...\n",
       "415     [[1, 1, 1, 1, 1, 1, 12, 74, 131, 210, 148, 116...\n",
       "733     [[255, 255, 255, 255, 255, 255, 255, 255, 255,...\n",
       "1653    [[1, 1, 1, 21, 57, 147, 158, 255, 255, 255, 25...\n",
       "                              ...                        \n",
       "1631    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 22, 34, 34, 13...\n",
       "248     [[255, 255, 255, 255, 255, 255, 255, 255, 255,...\n",
       "2595    [[232, 254, 255, 255, 62, 1, 1, 1, 1, 1, 1, 1,...\n",
       "1402    [[1, 1, 1, 1, 1, 1, 1, 1, 154, 255, 231, 23, 1...\n",
       "2416    [[24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, ...\n",
       "Length: 2180, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = IN_DATA['os']['train_x']\n",
    "# b = a.iloc[0]\n",
    "# ba = np.array(b)\n",
    "# aa = ba.reshape(20,20)\n",
    "# aa\n",
    "# cc = reshape_img(a.iloc[0])\n",
    "# cc.shape\n",
    "\n",
    "# old_df = IN_DATA['os']['train_x']\n",
    "# new_df = old_df.apply(lambda row: reshape_img(row), axis=1)\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "latest-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_img(img_data):\n",
    "    aa=np.array(img_data).reshape(20,20)\n",
    "    return K.constant(aa,shape=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlike-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DATA = dict()\n",
    "for k,df in RAW_INPUT_DICT.items():\n",
    "    x = df.loc[:, DATA_COLS]\n",
    "    y = df.loc[:, TARGET_COL]\n",
    "    m = df.loc[:, META_COLS]\n",
    "\n",
    "    x = x.apply(lambda row: reshape_img(row), axis=1)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2)\n",
    "#     X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2)\n",
    "    \n",
    "    i_data = dict()\n",
    "    i_data['train_x'] = X_train\n",
    "    i_data['train_y'] = Y_train\n",
    "#     i_data['val_x']   = X_val\n",
    "#     i_data['val_y']   = Y_val\n",
    "    i_data['test_x'] = X_test\n",
    "    i_data['test_y'] = Y_test\n",
    "    \n",
    "    IN_DATA[k] = i_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "removed-perth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_x': 980     ((tf.Tensor(96.0, shape=(), dtype=float32), tf...\n",
       " 455     ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " 839     ((tf.Tensor(255.0, shape=(), dtype=float32), t...\n",
       " 538     ((tf.Tensor(255.0, shape=(), dtype=float32), t...\n",
       " 2412    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       "                               ...                        \n",
       " 1065    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " 1428    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " 2435    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " 1203    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " 1685    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " Length: 2180, dtype: object,\n",
       " 'train_y':       font_class\n",
       " 980            0\n",
       " 455            1\n",
       " 839            0\n",
       " 538            1\n",
       " 2412           0\n",
       " ...          ...\n",
       " 1065           1\n",
       " 1428           0\n",
       " 2435           1\n",
       " 1203           0\n",
       " 1685           1\n",
       " \n",
       " [2180 rows x 1 columns],\n",
       " 'test_x': 379     ((tf.Tensor(214.0, shape=(), dtype=float32), t...\n",
       " 1185    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " 1225    ((tf.Tensor(111.0, shape=(), dtype=float32), t...\n",
       " 1692    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " 147     ((tf.Tensor(198.0, shape=(), dtype=float32), t...\n",
       "                               ...                        \n",
       " 488     ((tf.Tensor(232.0, shape=(), dtype=float32), t...\n",
       " 89      ((tf.Tensor(12.0, shape=(), dtype=float32), tf...\n",
       " 2532    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " 573     ((tf.Tensor(171.0, shape=(), dtype=float32), t...\n",
       " 421     ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n",
       " Length: 546, dtype: object,\n",
       " 'test_y':       font_class\n",
       " 379            0\n",
       " 1185           0\n",
       " 1225           1\n",
       " 1692           1\n",
       " 147            1\n",
       " ...          ...\n",
       " 488            1\n",
       " 89             1\n",
       " 2532           0\n",
       " 573            0\n",
       " 421            1\n",
       " \n",
       " [546 rows x 1 columns]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junk = IN_DATA['os']\n",
    "junk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-belly",
   "metadata": {},
   "source": [
    "## Setup Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "federal-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(nn_m, in_data, font_class):\n",
    "    #  Confusion Matrix\n",
    "    y_test_pred = nn_m.predict_classes(in_data['test_x'])\n",
    "    c_matrix = confusion_matrix(in_data['test_y'], y_test_pred)\n",
    "    ax = sns.heatmap(\n",
    "        c_matrix, \n",
    "        annot=True,\n",
    "        xticklabels=[f'Not {font_class}', f'{font_class}'],\n",
    "        yticklabels=[f'Not {font_class}', f'{font_class}'],\n",
    "        cbar=False,\n",
    "        cmap='Blues',\n",
    "        fmt='g'\n",
    "    )\n",
    "    ax.set_title(f'Confusion Matrix {font_class}')\n",
    "    ax.set_xlabel('Prediction')\n",
    "    ax.set_ylabel('Actual')\n",
    "    plt.savefig(f'Simple_CM_{font_class.replace(\" \",\"_\")}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roc(nn_m, in_data, font_class):\n",
    "    # ROC Curve\n",
    "    y_test_pred_probs = nn_m.predict(in_data['test_x'])\n",
    "    fpr, tpr, _ = roc_curve(in_data['test_y'], y_test_pred_probs)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1],[0,1],'--', color='black')\n",
    "    plt.title(f'ROC Curve {font_class}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.savefig(f'Simple_ROC_{font_class.replace(\" \",\"_\")}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def run_convo(in_data, font_class):\n",
    "    filter_size     = 3\n",
    "    n_filters       = 32\n",
    "    input_size      = 20\n",
    "    max_pool_size   = 2\n",
    "    batch_size      = 16\n",
    "    steps_per_epoch = 20000//batch_size\n",
    "    n_epochs        = 10\n",
    "    \n",
    "    # Setup Convolutional Neural Network\n",
    "    nn = Sequential()\n",
    "    nn.add(Conv2D(n_filters, (filter_size, filter_size), input_shape=(input_size, input_size, 1), activation='relu'))\n",
    "    nn.add(MaxPooling2D(pool_size=(max_pool_size, max_pool_size)))\n",
    "    nn.add(Conv2D(n_filters, (filter_size, filter_size), input_shape=(input_size/2, input_size/2, 1), activation='relu'))\n",
    "    nn.add(MaxPooling2D(pool_size=(max_pool_size, max_pool_size)))\n",
    "    nn.add(Flatten())\n",
    "    nn.add(Dense(units=128, activation='relu'))\n",
    "    nn.add(Dropout(0.5))\n",
    "    nn.add(Dense(units=1, activation='sigmoid'))\n",
    "    nn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    print(f'Start {datetime.now()}')\n",
    "    nn.fit(in_data['train_x'],in_data['train_y'], epochs=n_epochs,verbose=1)\n",
    "    print(f'Stop  {datetime.now()}')\n",
    "\n",
    "    scores = nn.evaluate(in_data['train_x'],in_data['train_y'])\n",
    "    print(f'Training Accurancy {scores[1]*100}')\n",
    "\n",
    "    scores = nn.evaluate(in_data['test_x'],in_data['test_y'])\n",
    "    print(f'Test Accurancy {scores[1]*100}')\n",
    "    \n",
    "    plot_cm(nn, in_data, font_class)\n",
    "    plot_roc(nn, in_data, font_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "inappropriate-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 2021-05-23 02:42:07.961862\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    465\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0;32m--> 466\u001b[0;31m                   (element, type(element).__name__))\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for 2118    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n1983    ((tf.Tensor(103.0, shape=(), dtype=float32), t...\n546     ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n825     ((tf.Tensor(92.0, shape=(), dtype=float32), tf...\n1785    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n                              ...                        \n855     ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n915     ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n2652    ((tf.Tensor(1.0, shape=(), dtype=float32), tf....\n1897    ((tf.Tensor(255.0, shape=(), dtype=float32), t...\n923     ((tf.Tensor(255.0, shape=(), dtype=float32), t...\nLength: 2180, dtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ea6bfbe7db30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     run_convo(v, tag_lu[k])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrun_convo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIN_DATA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'os'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Old Style'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-636d1d1127a6>\u001b[0m in \u001b[0;36mrun_convo\u001b[0;34m(in_data, font_class)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Start {datetime.now()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Stop  {datetime.now()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[1;32m    389\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m     ))\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    602\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m--> 604\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         normalized_components.append(\n\u001b[0;32m---> 98\u001b[0;31m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                          as_ref=False):\n\u001b[1;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 264\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/math-637/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor)."
     ]
    }
   ],
   "source": [
    "# tag_lu = {\n",
    "#     'os': 'Old Style',\n",
    "#     'tr': 'Transitional',\n",
    "#     'mo': 'Modern',\n",
    "#     'ss': 'Sans Serif'\n",
    "# }\n",
    "\n",
    "# for k,v in IN_DATA.items():\n",
    "#     run_convo(v, tag_lu[k])\n",
    "\n",
    "run_convo(IN_DATA['os'], 'Old Style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
